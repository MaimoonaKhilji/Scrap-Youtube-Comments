{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28f6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to scrape the comments of any Youtube video.\n",
    "\n",
    "Example:\n",
    "    $ python main.py YOUTUBE_VIDEO_URL\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import io\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "import sys\n",
    "import time\n",
    "from os.path import exists\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def scrape(url):\n",
    "    \"\"\"\n",
    "    Extracts the comments from the Youtube video given by the URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL to the Youtube video\n",
    "\n",
    "    Raises:\n",
    "        selenium.common.exceptions.NoSuchElementException:\n",
    "        When certain elements to look for cannot be found\n",
    "    \"\"\"\n",
    "\n",
    "    # Note: Download and replace argument with path to the driver executable.\n",
    "    # Simply download the executable and move it into the webdrivers folder.\n",
    "    driver = webdriver.Chrome('./webdrivers/chromedriver')\n",
    "\n",
    "    # Navigates to the URL, maximizes the current window, and\n",
    "    # then suspends execution for (at least) 5 seconds (this\n",
    "    # gives time for the page to load).\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        # Extract the elements storing the video title and\n",
    "        # comment section.\n",
    "        title = driver.find_element_by_xpath('//*[@id=\"container\"]/h1/yt-formatted-string').text\n",
    "        comment_section = driver.find_element_by_xpath('//*[@id=\"comments\"]')\n",
    "    except exceptions.NoSuchElementException:\n",
    "        # Note: Youtube may have changed their HTML layouts for\n",
    "        # videos, so raise an error for sanity sake in case the\n",
    "        # elements provided cannot be found anymore.\n",
    "        error = \"Error: Double check selector OR \"\n",
    "        error += \"element may not yet be on the screen at the time of the find operation\"\n",
    "        print(error)\n",
    "\n",
    "    # Scroll into view the comment section, then allow some time\n",
    "    # for everything to be loaded as necessary.\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", comment_section)\n",
    "    time.sleep(7)\n",
    "\n",
    "    # Scroll all the way down to the bottom in order to get all the\n",
    "    # elements loaded (since Youtube dynamically loads them).\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Scroll down 'til \"next load\".\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        # Wait to load everything thus far.\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height.\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # One last scroll just in case.\n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "    try:\n",
    "        # Extract the elements storing the usernames and comments.\n",
    "        username_elems = driver.find_elements_by_xpath('//*[@id=\"author-text\"]')\n",
    "        comment_elems = driver.find_elements_by_xpath('//*[@id=\"content-text\"]')\n",
    "    except exceptions.NoSuchElementException:\n",
    "        error = \"Error: Double check selector OR \"\n",
    "        error += \"element may not yet be on the screen at the time of the find operation\"\n",
    "        print(error)\n",
    "\n",
    "    print(\"> VIDEO TITLE: \" + title + \"\\n\")\n",
    "\n",
    "    try:\n",
    "        postdate = driver.find_element_by_css_selector(\"span#dot+yt-formatted-string\").get_attribute('innerHTML')\n",
    "        print(postdate)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    \n",
    "    #parse date\n",
    "    postdate= postdate.replace(',','')\n",
    "    if 'Streamed live on ' in postdate:\n",
    "        postdate= postdate.replace('Streamed live on ','')\n",
    "        \n",
    "    if 'Premiered ' in postdate:\n",
    "        postdate= postdate.replace('Premiered ','')\n",
    "        \n",
    "         \n",
    "    postdate=parse(postdate)\n",
    "    postdate=postdate.strftime('%d-%b-%Y')\n",
    "    a=postdate\n",
    "    \n",
    "    #file with link+date\n",
    "    with open('out.csv', 'a',newline=\"\") as f: # output csv file\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([url,postdate])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #result file\n",
    "    i=1\n",
    "    while(exists((a+\".csv\"))==True):\n",
    "        a=a+\"(\"+str(i)+\")\"\n",
    "        i=i+1\n",
    "        \n",
    "    a=a+\".csv\"\n",
    "    \n",
    "    with io.open(a, 'w', newline='', encoding=\"utf-16\") as file:\n",
    "        writer = csv.writer(file, delimiter =\",\", quoting=csv.QUOTE_ALL)\n",
    "        writer.writerow([\"Username\", \"Comment\"])\n",
    "        for username, comment in zip(username_elems, comment_elems):\n",
    "            writer.writerow([username.text, comment.text])\n",
    "\n",
    "   \n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ce3f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com/watch?v=pNPFnAq9XG8\n",
      "> VIDEO TITLE: DIGITEX Launch Party! Interview With CEO ADAM TODD [Cryptocurrency News Online]\n",
      "\n",
      "Streamed live on Jul 31, 2020\n",
      "https://www.youtube.com/watch?v=E9qFkTDpd2A\n",
      "> VIDEO TITLE: The NFL makes MAJOR Cryptocurrency Announcement for 2021 as Bloomberg Pumps Bitcoin AND Ethereum!\n",
      "\n",
      "Dec 29, 2020\n",
      "https://www.youtube.com/watch?v=-DUR5Ste-9I\n",
      "> VIDEO TITLE: “Bitcoin Could Be At $100,000 Next Week!” - Brekkie Von Bitcoin Talks SwanBitcoin, BTC Art & MORE!\n",
      "\n",
      "Feb 14, 2021\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('Altcoin Daily.csv') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        r=row['YouTube Link']\n",
    "        print(r) \n",
    "        scrape(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b328ac42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-Dec-2018\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "postdate='Premiered Dec 18, 2018'\n",
    "postdate= postdate.replace(',','')\n",
    "if 'Premiered ' in postdate:\n",
    "        postdate= postdate.replace('Premiered ','')\n",
    "postdate=parse(postdate)\n",
    "postdate=postdate.strftime('%d-%b-%Y')\n",
    "a=postdate\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeccddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
